# Core Dependencies
paddlepaddle==2.6.1
paddleocr==2.7.0.3
opencv-python-headless>=4.10.0.84
pdfplumber>=0.11.4
rapidfuzz>=3.10.0
unidecode>=1.3.8
pandas>=2.2.2
numpy>=1.26.4,<2.0
pydantic>=2.8.2
python-dotenv>=1.0.1
pillow>=10.0.0
requests>=2.31.0

# Web Framework
fastapi>=0.115.0
uvicorn[standard]>=0.30.6
jinja2>=3.1.2
python-multipart>=0.0.6
aiofiles>=23.2.0
httpx>=0.25.0

# LangChain ecosystem + monitoring
langchain==0.3.26
langchain-community==0.3.26
langchain-pinecone==0.2.8
langchain-text-splitters>=0.3.0
langsmith>=0.2.3
langchain-ollama>=0.1.0

# Pinecone + embeddings
pinecone
sentence-transformers==2.2.2

# Document processing
pypdf>=5.6.1
pymupdf<1.21.0
pytesseract>=0.3.10
protobuf<3.21


# Ollama client
ollama>=0.3.1

# Web search (renamed package)
ddgs>=2.5.1

# MCP Server
mcp>=1.0.0

# Multimodal processing (Transformers optional)
# (Install your CUDA-specific torch/torchvision manually if needed; we avoid pinning here to prevent Windows DLL issues)
transformers==4.24.0

# Hugging Face hub pinned for ST 2.2.2 + Transformers 4.24.0
huggingface-hub>=0.10,<0.14

# Utilities
tqdm>=4.66.0
loguru>=0.7.2
beautifulsoup4>=4.12.3
rapidfuzz>=3.1.1

# CLIP (OpenAI)
git+https://github.com/openai/CLIP.git



# Add these if you want enhanced performance/caching
diskcache>=5.6.0
orjson>=3.9.0

# System monitoring and caching
psutil>=5.9.0
cachetools>=5.3.0

# Enhanced async support
aiofiles>=23.2.0